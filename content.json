{"meta":{"title":"多多的小站","subtitle":"Chongqing, China","description":"DBA & DevOps","author":"何多多","url":"https://ddhe9527.github.io","root":"/"},"pages":[{"title":"关于我","date":"2019-12-03T13:23:14.000Z","updated":"2020-04-29T02:58:57.455Z","comments":false,"path":"about/index.html","permalink":"https://ddhe9527.github.io/about/index.html","excerpt":"","text":"&emsp;&emsp;自动化小硕一枚，搞过Linux C开发，后来转为专职DBA。擅长Oracle/MySQL相关的SQL开发与性能调优、数据库迁移升级、故障诊断处理等 姓名：何多多 位置：重庆 毕业：2014-07 微信：ddhe9527 邮箱：heduoduo321@163.com 标签：SQL, Oracle OCM, MySQL OCP, Redis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"},{"title":"文章分类","date":"2019-12-03T06:15:58.000Z","updated":"2020-04-26T08:26:23.521Z","comments":false,"path":"categories/index.html","permalink":"https://ddhe9527.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-12-03T07:17:10.000Z","updated":"2020-04-26T08:26:23.523Z","comments":false,"path":"tags/index.html","permalink":"https://ddhe9527.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MySQL的账号匹配规则","slug":"MySQL的账号匹配规则","date":"2020-03-31T05:34:00.000Z","updated":"2020-04-26T08:26:23.514Z","comments":true,"path":"2020/03/31/MySQL的账号匹配规则/","link":"","permalink":"https://ddhe9527.github.io/2020/03/31/MySQL%E7%9A%84%E8%B4%A6%E5%8F%B7%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99/","excerpt":"引言MySQL的账号由 &#39;用户名&#39;@&#39;主机或IP&#39; 构成，当用户连接匹配到mysql权限表中不同账号时，将被赋予对应的权限 1mysql&gt; select user,host from mysql.user;2+---------------+-----------+3| user | host |4+---------------+-----------+5| | |6| test | |7| | % |8| test | % |9| mysql.session | localhost |10| mysql.sys | localhost |11| root | localhost |12| | node1 |13| test | node1 |14+---------------+-----------+159 rows in set (0.00 sec)","text":"引言MySQL的账号由 &#39;用户名&#39;@&#39;主机或IP&#39; 构成，当用户连接匹配到mysql权限表中不同账号时，将被赋予对应的权限 1mysql&gt; select user,host from mysql.user;2+---------------+-----------+3| user | host |4+---------------+-----------+5| | |6| test | |7| | % |8| test | % |9| mysql.session | localhost |10| mysql.sys | localhost |11| root | localhost |12| | node1 |13| test | node1 |14+---------------+-----------+159 rows in set (0.00 sec) 现在有这样一种场景：mysql.user表中的内容如上所示，假设： &#39;&#39;@&#39;&#39; 账号具有A库上的ALL权限 &#39;test&#39;@&#39;&#39; 账号具有B库上的ALL权限 &#39;&#39;@&#39;%&#39; 账号户具有C库上的ALL权限 &#39;test&#39;@&#39;%&#39; 账号具有D库上的ALL权限 &#39;&#39;@&#39;node1&#39; 账号具有E库上的ALL权限 &#39;test&#39;@&#39;node1&#39; 账号具有F库上的ALL权限 此时如果使用’test’用户名从node1节点访问数据库，从账号匹配的角度来看，上述6个账号都能够被匹配到，但是只能选择其中一个，那么这个连接最终会匹配到哪个账号呢？ 分析官方文档Access Control, Stage 1: Connection Verification中有如下说明： When multiple matches are possible, the server must determine which of them to use. It resolves this issue as follows: Whenever the server reads the user table into memory, it sorts the rows. When a client attempts to connect, the server looks through the rows in sorted order. The server uses the first row that matches the client host name and user name. The server uses sorting rules that order rows with the most-specific Host values first. Literal host names and IP addresses are the most specific. 大致的意思是说，MySQL会首先对mysql.user表进行排序。当client试图连接数据库时，会扫描排序后的user表，一旦有账号被匹配到，便以此账号的身份给予权限，即选择第一个被匹配到的账号。排序规则为： 1select user,host from mysql.user order by host desc,user desc;2+---------------+-----------+3| user | host |4+---------------+-----------+5| test | node1 |6| | node1 |7| root | localhost |8| mysql.sys | localhost |9| mysql.session | localhost |10| test | % |11| | % |12| test | |13| | |14+---------------+-----------+159 rows in set (0.00 sec) 测试1，使用&#39;test&#39;用户名从node1节点连接数据库，看到current_user()函数输出为test@node1，即匹配到了&#39;test&#39;@&#39;node1&#39;账号 1[root@node1 ~]# mysql -utest -p123456 -h192.168.90.1102...3mysql&gt; select user(),current_user();4+------------+----------------+5| user() | current_user() |6+------------+----------------+7| test@node1 | test@node1 |8+------------+----------------+91 row in set (0.00 sec) 2，删除test@node1账号后再次尝试连接，current_user()函数输出变为@node1，即匹配到&#39;&#39;@&#39;node1&#39;账号 1[root@node1 ~]# mysql -uroot 2...3mysql&gt; drop user test@node1;4Query OK, 0 rows affected (0.00 sec)56mysql&gt; exit7Bye89[root@node1 ~]# mysql -utest -p123456 -h192.168.90.11010...11mysql&gt; select user(),current_user();12+------------+----------------+13| user() | current_user() |14+------------+----------------+15| test@node1 | @node1 |16+------------+----------------+171 row in set (0.00 sec) 3，删除&#39;&#39;@&#39;node1&#39;账号后再次尝试连接，current_user()函数输出变为test@%，即匹配到&#39;test&#39;@&#39;%&#39;账号 1[root@node1 ~]# mysql -uroot 2...3mysql&gt; drop user ''@'node1';4Query OK, 0 rows affected (0.00 sec)56mysql&gt; exit7Bye89[root@node1 ~]# mysql -utest -p123456 -h192.168.90.11010...11mysql&gt; select user(),current_user();12+------------+----------------+13| user() | current_user() |14+------------+----------------+15| test@node1 | test@% |16+------------+----------------+171 row in set (0.00 sec) 4，重复上述步骤，最终得到的current_user()函数输出顺序为： test@node1 @node1 test@% @% test@ @ 回过头来，再次看一下mysql.user表，排除host为localhost的3个账号，其顺序与上面的输出是完全一致的 1select user,host from mysql.user order by host desc,user desc;2+---------------+-----------+3| user | host |4+---------------+-----------+5| test | node1 |6| | node1 |7| root | localhost |8| mysql.sys | localhost |9| mysql.session | localhost |10| test | % |11| | % |12| test | |13| | |14+---------------+-----------+159 rows in set (0.00 sec) 总结 当一个客户端连接能够被mysql权限表中多个账号匹配到时，将按照“order by host desc,user desc”的顺序匹配排在最前面的那个账号，进而获得该账户对应的权限 当数据库中存在匿名账号时，例如&#39;&#39;@&#39;node1&#39;账号，它的匹配优先级是比较靠前的(比&#39;test&#39;@&#39;%&#39;账号高)，因此在使用匿名账号时要格外注意，避免用户连接被意外匹配到匿名账号上 参考https://dev.mysql.com/doc/refman/5.7/en/connection-access.html","categories":[{"name":"MySQL原理","slug":"MySQL原理","permalink":"https://ddhe9527.github.io/categories/MySQL%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://ddhe9527.github.io/tags/MySQL/"},{"name":"权限","slug":"权限","permalink":"https://ddhe9527.github.io/tags/%E6%9D%83%E9%99%90/"}]},{"title":"MySQL 8.0.18中的Hash Join","slug":"MySQL 8.0.18中的hash join","date":"2019-12-21T06:19:00.000Z","updated":"2020-04-26T08:26:23.512Z","comments":true,"path":"2019/12/21/MySQL 8.0.18中的hash join/","link":"","permalink":"https://ddhe9527.github.io/2019/12/21/MySQL%208.0.18%E4%B8%AD%E7%9A%84hash%20join/","excerpt":"概述在之前的版本中，MySQL已经把Nested Loop玩出了诸多花样(除普通NL外，还有BNL和BKA)。随着MySQL 8.0中统计直方图的完善，hash join终于出现在了MySQL 8.0.18版本中，用于替代性能较差的BNL。","text":"概述在之前的版本中，MySQL已经把Nested Loop玩出了诸多花样(除普通NL外，还有BNL和BKA)。随着MySQL 8.0中统计直方图的完善，hash join终于出现在了MySQL 8.0.18版本中，用于替代性能较差的BNL。 MySQL 8.0.18中hash join的使用前提条件包括如下3点： 表与表之间是等值内连接并且优化器决定在连接字段上不使用索引，或者是不包含任何连接条件的笛卡尔连接； 在满足“条件1”的前提下，表与表之间可以包含不等值连接条件； 如果SQL中任意两个表之间的连接不满足“条件1”，则该SQL中的所有JOIN都不能使用hash join； 为了在执行计划中看到”hash join”关键字，需要使用”EXPLAIN FORMAT=TREE”或”EXPLAIN ANALYZE”语句，否则看到的仍然是BNL(Block Nested Loop)，这点很容易产生误导。 hash join和BNL/BKA一样，都要使用到join buffer，其大小由join_buffer_size控制(默认256KB)，超过后会生成临时文件在磁盘上进行操作(文件操作又进一步涉及open_files_limit参数)。 为了支持hash join，MySQL的优化器选项中增加了如下配置： optimizer_switch中新增了hash join开关选项：hash_join，可以在global或session级别修改该参数； 新增2个hint：HASH_JOIN和NO_HASH_JOIN，用于在SQL级别控制hash join行为，但如果有合适的索引可用，HASH_JOIN这个hint仍然可能被忽略(从MySQL 8.0.19开始，这两个hint被置为无效)； 不适合使用hash join的场景 被驱动表的关联字段上存在筛选能力高的索引可用； 含有LIMIT子句，这时使用BNL能够提前结束表连接，而hash join在取LIMIT之前仍需要全部进行连接； 测试环境准备： 数据库版本确认为8.0.18，join_buffer_size为默认的256KB大小，optimizer_switch中的hash_join=on 创建三张表t1、t2和t3，各包含10万行数据，t1_val和t2_val字段中都是0 ~ 99之间的数字，t3_val字段中是0 ~ 49之间的数字，这三个字段上均没有索引 1mysql&gt; select version();2+-----------+3| version() |4+-----------+5| 8.0.18 |6+-----------+71 row in set (0.00 sec)89mysql&gt; show variables like 'join_buffer_size';10+------------------+--------+11| Variable_name | Value |12+------------------+--------+13| join_buffer_size | 262144 |14+------------------+--------+151 row in set (0.00 sec)1617mysql&gt; show variables like 'optimizer_switch'\\G18*************************** 1. row ***************************19Variable_name: optimizer_switch20 Value: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on,use_invisible_indexes=off,skip_scan=on,hash_join=on211 row in set (0.00 sec)2223mysql&gt; CREATE TABLE t1 (t1_id int unsigned NOT NULL auto_increment PRIMARY KEY, t1_val int unsigned, t1_str varchar(300));24Query OK, 0 rows affected (0.23 sec)2526mysql&gt; CREATE TABLE t2 (t2_id int unsigned NOT NULL auto_increment PRIMARY KEY, t2_val int unsigned,t2_str varchar(300));27Query OK, 0 rows affected (0.11 sec)2829mysql&gt; CREATE TABLE t3 (t3_id int unsigned NOT NULL auto_increment PRIMARY KEY, t3_val int unsigned,t3_str varchar(300));30Query OK, 0 rows affected (1.76 sec)3132mysql&gt; SET SESSION cte_max_recursion_depth = 100000;33Query OK, 0 rows affected (0.00 sec)3435mysql&gt; INSERT INTO t1 (t1_val) WITH RECURSIVE digits(i) AS (SELECT 1 UNION ALL SELECT i+1 FROM digits WHERE i&lt;100000) SELECT FLOOR(RAND()*100) FROM digits;36Query OK, 100000 rows affected (1.78 sec)37Records: 100000 Duplicates: 0 Warnings: 03839mysql&gt; INSERT INTO t2 (t2_val) WITH RECURSIVE digits(i) AS (SELECT 1 UNION ALL SELECT i+1 FROM digits WHERE i&lt;100000) SELECT FLOOR(RAND()*100) FROM digits;40Query OK, 100000 rows affected (1.87 sec)41Records: 100000 Duplicates: 0 Warnings: 04243mysql&gt; INSERT INTO t3 (t3_val) WITH RECURSIVE digits(i) AS (SELECT 1 UNION ALL SELECT i+1 FROM digits WHERE i&lt;100000) SELECT FLOOR(RAND()*50) FROM digits;44Query OK, 100000 rows affected (3.43 sec)45Records: 100000 Duplicates: 0 Warnings: 0 收集并查看统计信息直方图(非必要步骤) 1mysql&gt; ANALYZE TABLE t1 UPDATE HISTOGRAM ON t1_val WITH 100 BUCKETS;2+---------+-----------+----------+---------------------------------------------------+3| Table | Op | Msg_type | Msg_text |4+---------+-----------+----------+---------------------------------------------------+5| test.t1 | histogram | status | Histogram statistics created for column 't1_val'. |6+---------+-----------+----------+---------------------------------------------------+71 rows in set (0.32 sec)89mysql&gt; ANALYZE TABLE t2 UPDATE HISTOGRAM ON t2_val WITH 100 BUCKETS;10+---------+-----------+----------+---------------------------------------------------+11| Table | Op | Msg_type | Msg_text |12+---------+-----------+----------+---------------------------------------------------+13| test.t2 | histogram | status | Histogram statistics created for column 't2_val'. |14+---------+-----------+----------+---------------------------------------------------+151 rows in set (0.21 sec)1617mysql&gt; ANALYZE TABLE t3 UPDATE HISTOGRAM ON t3_val WITH 50 BUCKETS;18+---------+-----------+----------+---------------------------------------------------+19| Table | Op | Msg_type | Msg_text |20+---------+-----------+----------+---------------------------------------------------+21| test.t3 | histogram | status | Histogram statistics created for column 't3_val'. |22+---------+-----------+----------+---------------------------------------------------+231 row in set (1.74 sec)2425mysql&gt; SELECT TABLE_NAME,COLUMN_NAME,HISTOGRAM FROM INFORMATION_SCHEMA.COLUMN_STATISTICS WHERE TABLE_NAME IN('t1','t2','t3')\\G26*************************** 1. row ***************************27TABLE_NAME: t128COLUMN_NAME: t1_val29 HISTOGRAM: &#123;\"buckets\": [[0, 0.00906727224855187], [1, 0.019039626119010007], [2, 0.028880331753554506], [3, 0.03942864665613481], [4, 0.04921998420221169], [5, 0.05958728278041074], [6, 0.06911532385466035], [7, 0.07954844655081622], [8, 0.08952080042127436], [9, 0.09959189046866773], [10, 0.10972880463401792], [11, 0.11979989468141128], [12, 0.1296899684044234], [13, 0.13972814639283834], [14, 0.14984860452869933], [15, 0.1599855186940495], [16, 0.17020471300684573], [17, 0.1806542917324908], [18, 0.19029752501316485], [19, 0.2006319115323855], [20, 0.21106503422854136], [21, 0.22092219589257506], [22, 0.23048314902580308], [23, 0.24020866245392314], [24, 0.2503455766192733], [25, 0.2606470510795155], [26, 0.27015863612427593], [27, 0.2805423907319642], [28, 0.29061348077935756], [29, 0.301490916271722], [30, 0.3111012374934176], [31, 0.321254607688257], [32, 0.33055226434965773], [33, 0.34004739336492895], [34, 0.3500526592943655], [35, 0.36081490258030546], [36, 0.3701948393891522], [37, 0.3806937862032649], [38, 0.39117627698788837], [39, 0.4017739599789363], [40, 0.4112690889942075], [41, 0.42153765139547134], [42, 0.43180621379673517], [43, 0.44153172722485523], [44, 0.4515863612427594], [45, 0.4617232754081096], [46, 0.4715475250131649], [47, 0.48156924697209064], [48, 0.4915416008425488], [49, 0.501843075302791], [50, 0.5123584781463929], [51, 0.5219358873091101], [52, 0.5324183780937336], [53, 0.5423578199052134], [54, 0.5519023170089522], [55, 0.5616607424960507], [56, 0.5706621906266457], [57, 0.5808155608214851], [58, 0.5907220905739864], [59, 0.6008754607688258], [60, 0.6109794628751976], [61, 0.6217910742496051], [62, 0.631335571353344], [63, 0.641225645076356], [64, 0.651263823064771], [65, 0.6606108478146394], [66, 0.6706654818325436], [67, 0.68025934702475], [68, 0.6897544760400212], [69, 0.6995293575566088], [70, 0.7096169036334914], [71, 0.7195728014744603], [72, 0.7284261453396526], [73, 0.7379870984728806], [74, 0.7483543970510796], [75, 0.7585900473933651], [76, 0.7683649289099528], [77, 0.778501843075303], [78, 0.7888197735650344], [79, 0.7988579515534494], [80, 0.8090606898367564], [81, 0.8188191153238549], [82, 0.8286762769878886], [83, 0.8388461032122172], [84, 0.8491475776724594], [85, 0.8594984202211693], [86, 0.870326487625066], [87, 0.8800520010531862], [88, 0.8895635860979465], [89, 0.8993549236440234], [90, 0.9087348604528701], [91, 0.9184932859399686], [92, 0.9281365192206427], [93, 0.9390139547130071], [94, 0.9495951816745658], [95, 0.9594687993680887], [96, 0.969934834123223], [97, 0.9799071879936812], [98, 0.9900605581885206], [99, 1.0000000000000002]], \"data-type\": \"int\", \"null-values\": 0.0, \"collation-id\": 8, \"last-updated\": \"2019-12-20 07:10:36.951184\", \"sampling-rate\": 0.6069398964414872, \"histogram-type\": \"singleton\", \"number-of-buckets-specified\": 100&#125;30*************************** 2. row ***************************31TABLE_NAME: t232COLUMN_NAME: t2_val33 HISTOGRAM: &#123;\"buckets\": [[0, 0.010344656910461797], [1, 0.020293346092293475], [2, 0.03050601375987857], [3, 0.040520697563148605], [4, 0.050584877332497405], [5, 0.06086353962152085], [6, 0.07094421804622923], [7, 0.0807774166405438], [8, 0.09095708699740972], [9, 0.10044381382917293], [10, 0.11115144115754567], [11, 0.12060517067858971], [12, 0.13043836927290428], [13, 0.14055204500833185], [14, 0.15101219250631076], [15, 0.16181881176684104], [16, 0.17137153322004262], [17, 0.18148520895547018], [18, 0.19158238603553815], [19, 0.20095362227978425], [20, 0.21090231146161592], [21, 0.22083450198808802], [22, 0.2309151804127964], [23, 0.24089686690534726], [24, 0.2507465641550214], [25, 0.26132220224051744], [26, 0.2711718994901916], [27, 0.28136806850241713], [28, 0.29095378726633786], [29, 0.3012159509000017], [30, 0.31078517100856284], [31, 0.3203378924617644], [32, 0.33020408836679815], [33, 0.3400207883057531], [34, 0.3501509626965403], [35, 0.3595057002854268], [36, 0.36963587467621395], [37, 0.3792380920954943], [38, 0.38908778934516847], [39, 0.3987560013858871], [40, 0.4088366798105955], [41, 0.41792743891372863], [42, 0.4283545891009884], [43, 0.4382537823167413], [44, 0.4483179620860901], [45, 0.4588276055501478], [46, 0.4684463216247877], [47, 0.4783785121512598], [48, 0.48827770536701276], [49, 0.4977974295094951], [50, 0.5083070729735528], [51, 0.5186517298840146], [52, 0.5285014271336888], [53, 0.5386810974905547], [54, 0.54928973288677], [55, 0.5592714193793208], [56, 0.5693026018379505], [57, 0.579894738578806], [58, 0.5904538780089424], [59, 0.6006995429872467], [60, 0.6104337496494038], [61, 0.6205309267294717], [62, 0.629935160284437], [63, 0.6396198709805152], [64, 0.6496510534391449], [65, 0.6592697695137848], [66, 0.6691359654188186], [67, 0.6794311263632016], [68, 0.6892478263021565], [69, 0.6996089818679779], [70, 0.7095576710498096], [71, 0.7197538400620351], [72, 0.7299335104189011], [73, 0.7395687251489006], [74, 0.7493854250878556], [75, 0.7593671115804064], [76, 0.7696622725247894], [77, 0.7790335087690354], [78, 0.7890811898830247], [79, 0.7992278629291714], [80, 0.809457029252116], [81, 0.8196202009536224], [82, 0.8290904291300261], [83, 0.838907129068981], [84, 0.8489053142168914], [85, 0.860058405239973], [86, 0.8702710729075581], [87, 0.8803517513322665], [88, 0.8914388477339098], [89, 0.9011730543960669], [90, 0.910544290640313], [91, 0.92027849730247], [92, 0.9298807147217504], [93, 0.9403738595304485], [94, 0.9505205325765952], [95, 0.9599742620976393], [96, 0.9698239593473134], [97, 0.9796571579416279], [98, 0.9898038309877746], [99, 1.0]], \"data-type\": \"int\", \"null-values\": 0.0, \"collation-id\": 8, \"last-updated\": \"2019-12-20 07:11:40.258403\", \"sampling-rate\": 0.6069398964414872, \"histogram-type\": \"singleton\", \"number-of-buckets-specified\": 100&#125;34*************************** 3. row ***************************35TABLE_NAME: t336COLUMN_NAME: t3_val37 HISTOGRAM: &#123;\"buckets\": [[0, 0.02045], [1, 0.041569999999999996], [2, 0.06140999999999999], [3, 0.08099999999999999], [4, 0.10089], [5, 0.12076999999999999], [6, 0.14067], [7, 0.16113], [8, 0.18152], [9, 0.20198999999999998], [10, 0.22208999999999998], [11, 0.24156], [12, 0.26165], [13, 0.28160999999999997], [14, 0.30163999999999996], [15, 0.32105999999999996], [16, 0.34131999999999996], [17, 0.36146999999999996], [18, 0.38072999999999996], [19, 0.40054999999999996], [20, 0.42157999999999995], [21, 0.44176999999999994], [22, 0.46115999999999996], [23, 0.48172], [24, 0.50109], [25, 0.52171], [26, 0.54217], [27, 0.5621], [28, 0.58143], [29, 0.60137], [30, 0.6214099999999999], [31, 0.6411899999999999], [32, 0.6616299999999999], [33, 0.6814199999999999], [34, 0.7012299999999999], [35, 0.7212699999999999], [36, 0.7411899999999999], [37, 0.76089], [38, 0.7811199999999999], [39, 0.8009499999999999], [40, 0.8204999999999999], [41, 0.8404599999999999], [42, 0.8609899999999999], [43, 0.8805099999999999], [44, 0.9009199999999999], [45, 0.9204399999999999], [46, 0.94136], [47, 0.96039], [48, 0.9805499999999999], [49, 0.9999999999999999]], \"data-type\": \"int\", \"null-values\": 0.0, \"collation-id\": 8, \"last-updated\": \"2019-12-20 07:41:17.446201\", \"sampling-rate\": 1.0, \"histogram-type\": \"singleton\", \"number-of-buckets-specified\": 50&#125;383 rows in set (0.00 sec) 测试如何查看hash join：EXPLAIN FORMAT=TREE 1##直接使用EXPLAIN仅能看到\"Block Nested Loop\"关键字2mysql&gt; EXPLAIN3 -&gt; SELECT * FROM t1,t2,t34 -&gt; WHERE t2.t2_val = t1.t1_val and t1.t1_val=t3.t3_val;5+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+6| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |7+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+8| 1 | SIMPLE | t1 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 100.00 | NULL |9| 1 | SIMPLE | t2 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 10.00 | Using where; Using join buffer (Block Nested Loop) |10| 1 | SIMPLE | t3 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 10.00 | Using where; Using join buffer (Block Nested Loop) |11+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+123 rows in set, 1 warning (0.00 sec)1314##只有使用\"EXPLAIN FORMAT=TREE\"才能看到\"Inner hash join\"关键字，下面输出可以看出3张表按照t1-&gt;t2-&gt;t3的顺序进行关联，两两之间均为hash join15mysql&gt; EXPLAIN FORMAT=TREE16 -&gt; SELECT * FROM t1,t2,t317 -&gt; WHERE t2.t2_val = t1.t1_val and t1.t1_val=t3.t3_val\\G18*************************** 1. row ***************************19EXPLAIN: -&gt; Inner hash join (t3.t3_val = t1.t1_val) (cost=10141380914795.79 rows=10139847189164)20 -&gt; Table scan on t3 (cost=0.52 rows=100464)21 -&gt; Hash22 -&gt; Inner hash join (t2.t2_val = t1.t1_val) (cost=1009337794.31 rows=1009301545)23 -&gt; Table scan on t2 (cost=0.27 rows=100464)24 -&gt; Hash25 -&gt; Table scan on t1 (cost=10102.65 rows=100464)26271 row in set (0.00 sec) 测试hint与索引的效果：索引的优先级高于hint 1##尝试让t1和t2之间进行hash join，t2和t3之间不使用hash join，但是EXPLAIN FORMAT=TREE未看到输出结果，使用EXPLAIN看到的是BNL连接方式2mysql&gt; EXPLAIN FORMAT=TREE3 -&gt; SELECT /*+HASH_JOIN(t1,t2) NO_HASH_JOIN(t2,t3)*/ * FROM t1,t2,t34 -&gt; WHERE t2.t2_val = t1.t1_val and t1.t1_val=t3.t3_val\\G5*************************** 1. row ***************************6EXPLAIN: &lt;not executable by iterator executor&gt;781 row in set, 1 warning (0.00 sec)910mysql&gt; EXPLAIN11 -&gt; SELECT /*+HASH_JOIN(t1,t2) NO_HASH_JOIN(t2,t3)*/ * FROM t1,t2,t312 -&gt; WHERE t2.t2_val = t1.t1_val and t1.t1_val=t3.t3_val;13+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+14| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |15+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+16| 1 | SIMPLE | t1 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 100.00 | NULL |17| 1 | SIMPLE | t2 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 10.00 | Using where; Using join buffer (Block Nested Loop) |18| 1 | SIMPLE | t3 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 10.00 | Using where; Using join buffer (Block Nested Loop) |19+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+203 rows in set, 2 warnings (0.00 sec)2122##在t3表的t3_val字段上创建索引，尝试用HASH_JOIN(t1,t3)强制使用hash join，发现hint被忽略，t3作为被驱动表使用了idx_t3_val索引23mysql&gt; create index idx_t3_val on t3(t3_val);24Query OK, 0 rows affected (0.58 sec)25Records: 0 Duplicates: 0 Warnings: 02627mysql&gt; EXPLAIN FORMAT=TREE28 -&gt; SELECT /*+HASH_JOIN(t1,t3)*/ * FROM t1,t329 -&gt; WHERE t1.t1_val=t3.t3_val\\G30*************************** 1. row ***************************31EXPLAIN: -&gt; Nested loop inner join (cost=37990517.85 rows=210271152)32 -&gt; Filter: (t1.t1_val is not null) (cost=10102.65 rows=100464)33 -&gt; Table scan on t1 (cost=10102.65 rows=100464)34 -&gt; Index lookup on t3 using idx_t3_val (t3_val=t1.t1_val) (cost=168.75 rows=2093)35361 row in set (0.00 sec)3738##测试完清理索引39mysql&gt; alter table t3 drop index idx_t3_val;40Query OK, 0 rows affected (0.16 sec)41Records: 0 Duplicates: 0 Warnings: 0 测试笛卡尔连接：支持hash join 1mysql&gt; EXPLAIN FORMAT=TREE2 -&gt; SELECT * FROM t1,t2\\G3*************************** 1. row ***************************4EXPLAIN: -&gt; Inner hash join (cost=1009337794.31 rows=10093015296)5 -&gt; Table scan on t2 (cost=0.36 rows=100464)6 -&gt; Hash7 -&gt; Table scan on t1 (cost=10102.65 rows=100464)891 row in set (0.00 sec) 测试外连接：不支持hash join，退化为BNL 1mysql&gt; EXPLAIN FORMAT=TREE2 -&gt; SELECT * FROM t1 JOIN t2 ON t2.t2_val = t1.t1_val3 -&gt; LEFT JOIN t3 ON t1.t1_val=t3.t3_val\\G4*************************** 1. row ***************************5EXPLAIN: &lt;not executable by iterator executor&gt;671 row in set (0.00 sec)89mysql&gt; EXPLAIN10 -&gt; SELECT * FROM t1 JOIN t2 ON t2.t2_val = t1.t1_val11 -&gt; LEFT JOIN t3 ON t1.t1_val=t3.t3_val;12+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+13| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |14+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+15| 1 | SIMPLE | t1 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 100.00 | NULL |16| 1 | SIMPLE | t2 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 10.00 | Using where; Using join buffer (Block Nested Loop) |17| 1 | SIMPLE | t3 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 100.00 | Using where; Using join buffer (Block Nested Loop) |18+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+193 rows in set, 1 warning (0.00 sec) 测试不等值连接：不支持hash join，退化为BNL 1##SQL中只要有一个不等值连接，整个SQL中的所有连接都不会使用hash join2mysql&gt; EXPLAIN FORMAT=TREE3 -&gt; SELECT * FROM t1 JOIN t2 ON t2.t2_val = t1.t1_val4 -&gt; JOIN t3 ON t1.t1_val &gt; t3.t3_val\\G5*************************** 1. row ***************************6EXPLAIN: &lt;not executable by iterator executor&gt;781 row in set (0.00 sec)910mysql&gt; EXPLAIN11 -&gt; SELECT * FROM t1 JOIN t2 ON t2.t2_val = t1.t1_val12 -&gt; JOIN t3 ON t1.t1_val&gt;t3.t3_val;13+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+14| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |15+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+16| 1 | SIMPLE | t1 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 100.00 | NULL |17| 1 | SIMPLE | t2 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 10.00 | Using where; Using join buffer (Block Nested Loop) |18| 1 | SIMPLE | t3 | NULL | ALL | NULL | NULL | NULL | NULL | 100464 | 33.33 | Using where; Using join buffer (Block Nested Loop) |19+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+203 rows in set, 1 warning (0.01 sec)2122##在满足全部为等值内连接的前提下，可以同时包含不等值连接条件23mysql&gt; EXPLAIN FORMAT=TREE24 -&gt; SELECT * FROM t1 JOIN t2 ON t2.t2_val = t1.t1_val25 -&gt; JOIN t3 ON t1.t1_val = t3.t3_val and t1.t1_id &gt; t3_id\\G26*************************** 1. row ***************************27EXPLAIN: -&gt; Inner hash join (t2.t2_val = t1.t1_val) (cost=3380795229097.44 rows=3379611112797)28 -&gt; Table scan on t2 (cost=0.52 rows=100464)29 -&gt; Hash30 -&gt; Nested loop inner join (cost=1009337794.31 rows=336400209)31 -&gt; Table scan on t1 (cost=10102.65 rows=100464)32 -&gt; Filter: ((t3.t3_val = t1.t1_val) and (t1.t1_id &gt; t3.t3_id)) (cost=0.26 rows=3348)33 -&gt; Index range scan on t3 (re-planned for each iteration) (cost=0.26 rows=100464) 测试非连接字段使用索引的情况：非连接字段可以使用索引，可以同时使用hash join 1mysql&gt; EXPLAIN FORMAT=TREE2 -&gt; SELECT * FROM t1 JOIN t2 ON t2.t2_val = t1.t1_val3 -&gt; JOIN t3 ON t1.t1_val=t3.t3_val and t1.t1_id&gt;5000\\G4*************************** 1. row ***************************5EXPLAIN: -&gt; Inner hash join (t3.t3_val = t1.t1_val) (cost=5070690462463.22 rows=5069923594582)6 -&gt; Table scan on t3 (cost=0.52 rows=100464)7 -&gt; Hash8 -&gt; Inner hash join (t2.t2_val = t1.t1_val) (cost=504673934.36 rows=504650772)9 -&gt; Table scan on t2 (cost=0.28 rows=100464)10 -&gt; Hash11 -&gt; Filter: (t1.t1_id &gt; 5000) (cost=10060.40 rows=50232)12 -&gt; Index range scan on t1 using PRIMARY (cost=10060.40 rows=50232) 测试join buffer大小对hash join性能的影响 1mysql&gt; EXPLAIN FORMAT=TREE2 -&gt; SELECT count(*) FROM t1,t23 -&gt; WHERE t2.t2_val = t1.t1_val\\G4*************************** 1. row ***************************5EXPLAIN: -&gt; Aggregate: count(0)6 -&gt; Inner hash join (t2.t2_val = t1.t1_val) (cost=1009311796.29 rows=1009301545)7 -&gt; Table scan on t2 (cost=0.01 rows=100464)8 -&gt; Hash9 -&gt; Table scan on t1 (cost=10102.65 rows=100464)10111 row in set (0.11 sec)1213##以如下形式，在会话级修改join_buffer_size为不同的值，测试SQL语句执行时长14set join_buffer_size=1024*1024*4;15SELECT count(*) FROM t1,t2 WHERE t2.t2_val = t1.t1_val;16SELECT count(*) FROM t1,t2 WHERE t2.t2_val = t1.t1_val;17SELECT count(*) FROM t1,t2 WHERE t2.t2_val = t1.t1_val;18SELECT count(*) FROM t1,t2 WHERE t2.t2_val = t1.t1_val;19SELECT count(*) FROM t1,t2 WHERE t2.t2_val = t1.t1_val; 测试结果：join_buffer_size不是越大越好，这应该与malloc函数选择使用brk还是mmap系统调用分配内存的方式有关 join_buffer_size 执行时长 32KB 4.04~4.37s 64KB 4.22~4.43s 128KB 4.24~4.50s 256KB 4.24~4.67s 512KB 4.19~4.59s 1MB 4.17~4.74s 2MB 4.77~5.28s 4MB 5.15~6.35s 8MB 7.39s~7.73s 16MB 11.15s~11.95s 与BNL的性能比较 1##使用hash join，从上面的测试结果可以看到，执行时间在4~5秒之间2SELECT count(*) FROM t1,t2 WHERE t2.t2_val = t1.t1_val;34##使用BNL，执行10分钟未返回结果，最终放弃了5SELECT /*+NO_HASH_JOIN(t1,t2)*/ count(*) FROM t1,t2 WHERE t2.t2_val = t1.t1_val; Optimizer Trace视角：未发现特征信息，这里不贴trace了，太长了… 参考How to Use Hash Joins? (文档 ID 2562434.1) https://dev.mysql.com/doc/refman/8.0/en/hash-joins.html","categories":[{"name":"SQL优化","slug":"SQL优化","permalink":"https://ddhe9527.github.io/categories/SQL%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"SQL优化","slug":"SQL优化","permalink":"https://ddhe9527.github.io/tags/SQL%E4%BC%98%E5%8C%96/"},{"name":"MySQL","slug":"MySQL","permalink":"https://ddhe9527.github.io/tags/MySQL/"},{"name":"执行计划","slug":"执行计划","permalink":"https://ddhe9527.github.io/tags/%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/"}]},{"title":"open_files_limit参数真实值测试","slug":"open_files_limit参数真实值测试","date":"2019-12-16T13:33:00.000Z","updated":"2020-04-26T08:26:23.515Z","comments":true,"path":"2019/12/16/open_files_limit参数真实值测试/","link":"","permalink":"https://ddhe9527.github.io/2019/12/16/open_files_limit%E5%8F%82%E6%95%B0%E7%9C%9F%E5%AE%9E%E5%80%BC%E6%B5%8B%E8%AF%95/","excerpt":"参数说明open_files_limit参数限制了mysqld进程能够打开的操作系统文件描述符(fd)的最大数量，如果没有显式设置这个参数值，它的默认值取如下四种值中的最大值(版本&gt;=5.6.8)： 10 + max_connections + (table_open_cache * 2) max_connections * 5 操作系统设置的open files的上限值(启动mysqld的操作系统用户的ulimit -n) 5000","text":"参数说明open_files_limit参数限制了mysqld进程能够打开的操作系统文件描述符(fd)的最大数量，如果没有显式设置这个参数值，它的默认值取如下四种值中的最大值(版本&gt;=5.6.8)： 10 + max_connections + (table_open_cache * 2) max_connections * 5 操作系统设置的open files的上限值(启动mysqld的操作系统用户的ulimit -n) 5000 如果显式设置了open_files_limit参数的值，则它的真实值为下面三种值中的最大值(版本&gt;=5.6.8)： 10 + max_connections + (table_open_cache * 2) max_connections * 5 open_files_limit显式设置的值 事实上，mysqld内部是使用setrlimit系统调用函数来设置自己的资源使用限制，如果它设置的值超过操作系统limit限制，则setrlimit会报错，上限即以OS的limit限制为准；如果它低于OS的limit限制，则以它设置的值为准。但是如果mysqld是使用root启动的，则不会发生此类情况 open_files_limit是全局静态参数，因此即使修改了动态参数table_open_cache或max_connections，open_files_limit的值也不会立即变化，只有重启mysqld以后才生效 注意使用ulimit -n XXX修改操作系统limit仅对当前会话生效，该命令可以写在/etc/profile中，使每个会话登录时自动执行，也可以在/etc/security/limits.conf文件中进行配置(nofile，最大1048576) 测试初始环境：未显式设置open_files_limit参数值的大小 1[root@rhel6 ~]# cat /etc/my.cnf | grep limit2[root@rhel6 ~]# ulimit -n3102445mysql&gt; show variables like 'table_open_cache';6+------------------+-------+7| Variable_name | Value |8+------------------+-------+9| table_open_cache | 2000 |10+------------------+-------+111 row in set (0.72 sec)1213mysql&gt; show variables like 'max_connections';14+-----------------+-------+15| Variable_name | Value |16+-----------------+-------+17| max_connections | 151 |18+-----------------+-------+191 row in set (0.00 sec)2021--------------------------------------------------------------------------2210 + max_connections + (table_open_cache * 2) = 10 + 151 + 2000 * 2 = 416123max_connections * 5 = 151 * 5 = 75524操作系统上限102425--------------------------------------------------------------------------2627根据规律，open_files_limit值应当为5000，验证结果28mysql&gt; show variables like 'open_files_limit';29+------------------+-------+30| Variable_name | Value |31+------------------+-------+32| open_files_limit | 5000 |33+------------------+-------+341 row in set (0.00 sec) 设置table_open_cache=3000并重启mysqld 1[root@rhel6 ~]# cat /etc/my.cnf | grep cache2table_open_cache=30003[root@rhel6 ~]# service mysqld restart4Shutting down MySQL.. [ OK ]5Starting MySQL. [ OK ]67--------------------------------------------------------------------------810 + max_connections + (table_open_cache * 2) = 10 + 151 + 3000 * 2 = 61619max_connections * 5 = 151 * 5 = 75510操作系统上限102411--------------------------------------------------------------------------1213mysql&gt; show variables like 'open_files_limit';14+------------------+-------+15| Variable_name | Value |16+------------------+-------+17| open_files_limit | 6161 |18+------------------+-------+191 row in set (0.00 sec) 设置max_connections=2000并重启mysqld(table_open_cache恢复成默认值2000) 1[root@rhel6 ~]# cat /etc/my.cnf | grep connections2max_connections=20003[root@rhel6 ~]# service mysqld restart4Shutting down MySQL.. [ OK ]5Starting MySQL. [ OK ]67--------------------------------------------------------------------------810 + max_connections + (table_open_cache * 2) = 10 + 151 + 2000 * 2 = 41619max_connections * 5 = 2000 * 5 = 1000010操作系统上限102411--------------------------------------------------------------------------1213mysql&gt; show variables like 'open_files_limit';14+------------------+-------+15| Variable_name | Value |16+------------------+-------+17| open_files_limit | 10000 |18+------------------+-------+191 row in set (0.00 sec) 设置操作系统ulimit -n 65536并重启mysqld(max_connections恢复成默认值151) 1[root@rhel6 ~]# ulimit -n210243[root@rhel6 ~]# ulimit -n 655364[root@rhel6 ~]# ulimit -n5655366[root@rhel6 ~]# service mysqld restart7Shutting down MySQL.. [ OK ]8Starting MySQL. [ OK ]910--------------------------------------------------------------------------1110 + max_connections + (table_open_cache * 2) = 10 + 151 + 2000 * 2 = 416112max_connections * 5 = 151 * 5 = 75513操作系统上限6553614--------------------------------------------------------------------------1516mysql&gt; show variables like 'open_files_limit';17+------------------+-------+18| Variable_name | Value |19+------------------+-------+20| open_files_limit | 65536 |21+------------------+-------+221 row in set (0.01 sec) 恢复操作系统ulimit -n 1024，同时恢复table_open_cache和max_connections为默认值，显式设置open_files_limit=10000 1[root@rhel6 ~]# ulimit -n 10242[root@rhel6 ~]# ulimit -n310244[root@rhel6 ~]# cat /etc/my.cnf | grep limit5open_files_limit=100006[root@rhel6 ~]# service mysqld restart7Shutting down MySQL.. [ OK ]8Starting MySQL. [ OK ]910--------------------------------------------------------------------------1110 + max_connections + (table_open_cache * 2) = 10 + 151 + 2000 * 2 = 416112max_connections * 5 = 151 * 5 = 75513操作系统上限102414open_files_limit=1000015--------------------------------------------------------------------------1617mysql&gt; show variables like 'open_files_limit';18+------------------+-------+19| Variable_name | Value |20+------------------+-------+21| open_files_limit | 10000 |22+------------------+-------+231 row in set (0.00 sec) 显式设置open_files_limit=200，其它均保持默认值 1[root@rhel6 ~]# cat /etc/my.cnf | grep limit2open_files_limit=2003[root@rhel6 ~]# service mysqld restart4Shutting down MySQL.. [ OK ]5Starting MySQL. [ OK ]678--------------------------------------------------------------------------910 + max_connections + (table_open_cache * 2) = 10 + 151 + 2000 * 2 = 416110max_connections * 5 = 151 * 5 = 75511操作系统上限102412open_files_limit=20013--------------------------------------------------------------------------1415mysql&gt; show variables like 'open_files_limit';16+------------------+-------+17| Variable_name | Value |18+------------------+-------+19| open_files_limit | 4161 |20+------------------+-------+211 row in set (0.00 sec) 显式设置open_files_limit=200，同时设置操作系统ulimit -n 65536并重启mysqld 1[root@rhel6 ~]# ulimit -n 655362[root@rhel6 ~]# ulimit -n3655364[root@rhel6 ~]# cat /etc/my.cnf | grep limit5open_files_limit=2006[root@rhel6 ~]# service mysqld restart7Shutting down MySQL.. [ OK ]8Starting MySQL. [ OK ]910--------------------------------------------------------------------------1110 + max_connections + (table_open_cache * 2) = 10 + 151 + 2000 * 2 = 416112max_connections * 5 = 151 * 5 = 75513操作系统上限6553614open_files_limit=20015--------------------------------------------------------------------------1617mysql&gt; show variables like 'open_files_limit';18+------------------+-------+19| Variable_name | Value |20+------------------+-------+21| open_files_limit | 4161 |22+------------------+-------+231 row in set (0.00 sec) referencehttps://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_open_files_limit","categories":[{"name":"MySQL原理","slug":"MySQL原理","permalink":"https://ddhe9527.github.io/categories/MySQL%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://ddhe9527.github.io/tags/MySQL/"},{"name":"参数","slug":"参数","permalink":"https://ddhe9527.github.io/tags/%E5%8F%82%E6%95%B0/"}]},{"title":"MySQL内存使用分析","slug":"MySQL内存使用分析","date":"2019-12-11T13:43:34.000Z","updated":"2020-04-26T08:26:23.513Z","comments":true,"path":"2019/12/11/MySQL内存使用分析/","link":"","permalink":"https://ddhe9527.github.io/2019/12/11/MySQL%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E5%88%86%E6%9E%90/","excerpt":"mysqld的内存使用策略mysqld启动前状态：OS总内存1985MB，已使用280MB，空闲941MB，Swap空间未使用 1[root@bogon ~]# ps -ef | grep mysqld2root 69294 68350 0 09:35 pts/0 00:00:00 grep mysqld3[root@bogon ~]# free -m4 total used free shared buff/cache available5Mem: 1985 280 941 8 763 15436Swap: 2047 0 2047","text":"mysqld的内存使用策略mysqld启动前状态：OS总内存1985MB，已使用280MB，空闲941MB，Swap空间未使用 1[root@bogon ~]# ps -ef | grep mysqld2root 69294 68350 0 09:35 pts/0 00:00:00 grep mysqld3[root@bogon ~]# free -m4 total used free shared buff/cache available5Mem: 1985 280 941 8 763 15436Swap: 2047 0 2047 buffer_pool配置的大小是512MB 1[root@bogon ~]# cat /etc/my.cnf | grep innodb_buffer_pool_size2innodb_buffer_pool_size=512m mysqld启动后：内存使用增加至478MB，增加了198MB，Swap无变化，buff/cache增长了12MB 1[root@bogon ~]# ps -ef | grep mysqld2root 69315 1 21 09:36 pts/0 00:00:01 /bin/sh /usr/local/mysql/bin/mysqld_safe --datadir=/mysql_data --pid-file=/mysql_data/rhel6.pid3mysql 69628 69315 8 09:36 pts/0 00:00:00 /usr/local/mysql/bin/mysqld --basedir=/usr/local/mysql --datadir=/mysql_data --plugin-dir=/usr/local/mysql/lib/plugin --user=mysql --log-error=error.log --pid-file=/mysql_data/rhel6.pid --socket=/mysql_data/mysql.sock --port=33064root 69663 68350 0 09:37 pts/0 00:00:00 grep mysqld5[root@bogon ~]# free -m6 total used free shared buff/cache available7Mem: 1985 478 731 8 775 13458Swap: 2047 0 2047 备注： total：内存总数 used：已经使用的内存数 free：空闲的内存数 shared：多个进程共享的内存总额 buffers：系统分配但未被使用的buffers大小 cached：Page 系统分配但未被使用的cache大小 使用TOP命令观察mysqld进程的内存使用，看到常驻内存占用211MB，虚拟内存1506MB 1iB Mem : 2033528 total, 740804 free, 498444 used, 794280 buff/cache2KiB Swap: 2097148 total, 2097148 free, 0 used. 1369180 avail Mem 34 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5 69628 mysql 20 0 1541944 216396 7116 S 0.0 10.6 0:00.56 mysqld 备注： PR：优先级 NI：nice值，负值表示高优先级，正值表示低优先级 VIRT：虚拟内存大小 RES：常驻内存大小，是进程当前使用的内存大小，包含其他进程的共享内存，不包括swap out SHR：共享内存大小 查看启动后buffer pool的情况 1mysql&gt; SHOW variables LIKE 'innodb_buffer_pool_size';2+-------------------------+-----------+3| Variable_name | Value |4+-------------------------+-----------+5| innodb_buffer_pool_size | 536870912 |6+-------------------------+-----------+71 row in set (0.00 sec)89mysql&gt; SHOW GLOBAL STATUS LIKE 'innodb_buffer_pool_pages_total';10+--------------------------------+-------+11| Variable_name | Value |12+--------------------------------+-------+13| Innodb_buffer_pool_pages_total | 32764 |14+--------------------------------+-------+151 row in set (0.03 sec)1617mysql&gt; SHOW GLOBAL STATUS LIKE 'innodb_buffer_pool_pages_free';18+-------------------------------+-------+19| Variable_name | Value |20+-------------------------------+-------+21| Innodb_buffer_pool_pages_free | 30142 |22+-------------------------------+-------+231 row in set (0.01 sec) sys schema中提供了直接查看内存使用的VIEW，当然前提是要先开启performance_schema中的对应instrument和consumer，好在sys提供了存储过程帮我们一键开启： 1CALL sys.ps_setup_enable_instrument('wait');2CALL sys.ps_setup_enable_instrument('stage');3CALL sys.ps_setup_enable_instrument('statement');4CALL sys.ps_setup_enable_consumer('current');5CALL sys.ps_setup_enable_consumer('history_long'); 开启以后，查看memory_global_total即可 1mysql&gt; select * from sys.memory_global_total;2+-----------------+3| total_allocated |4+-----------------+5| 132.01 MiB |6+-----------------+71 row in set (0.01 sec) 为了测试内存波动，现把官方的测试库load进去： 1[root@bogon test_db-master]# mysql -uroot -p123456 &lt; employees.sql2mysql: [Warning] Using a password on the command line interface can be insecure.3INFO4CREATING DATABASE STRUCTURE5INFO6storage engine: InnoDB7INFO8LOADING departments9INFO10LOADING employees11INFO12LOADING dept_emp13INFO14LOADING dept_manager15INFO16LOADING titles17INFO18LOADING salaries19data_load_time_diff2000:01:0821[root@bogon test_db-master]# 再次查看OS层面的内存使用情况，发现常驻内存占用409MB(增加了198MB)，虚拟内存1544MB(增加了38MB) 1KiB Mem : 2033528 total, 286280 free, 699384 used, 1047864 buff/cache2KiB Swap: 2097148 total, 2097148 free, 0 used. 1165152 avail Mem 34 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 5 69628 mysql 20 0 1580688 418448 9284 S 0.0 20.6 1:05.71 mysqld 再次查看buffer pool和内存的使用情况，看到free page减少至22818(减少了7324个page，对应114MB)，但sys.memory_global_total查到的仅增加了9MB左右内存(感觉这个VIEW的结果不太准确) 1mysql&gt; SHOW GLOBAL STATUS LIKE 'innodb_buffer_pool_pages_free';2+-------------------------------+-------+3| Variable_name | Value |4+-------------------------------+-------+5| Innodb_buffer_pool_pages_free | 22818 |6+-------------------------------+-------+71 row in set (0.00 sec)89mysql&gt; select * from sys.memory_global_total;10+-----------------+11| total_allocated |12+-----------------+13| 141.07 MiB |14+-----------------+151 row in set (0.00 sec) 从上述现象可以看出： mysqld启动以后，仅在虚拟内存中分配了所需要的地址空间，并没有真正的映射到物理内存上(否则mysqld的内存占用会立即大于innodb_buffer_pool_size设定的512MB)，而是在使用过程中再映射到物理内存，如果物理内存(内存+swap)不足了，就会出错甚至退出 Why is MySQL Using Less Memory Than Configured? (文档 ID 1483601.1) On Linux the operating system is not necessarily physically allocating the memory when it is requested. This is done as generally processes request more memory than it actually will end up using. So by defering the actual allocation of memory, work is reduced and it is possible to allow more processes than would fit into memory if all processes used the full amount of memory requested. Other operating systems uses different strategies, each with its pros and cons. MySQL的内存分配相关参数共享内存1mysql&gt; select version();2+------------+3| version() |4+------------+5| 5.7.25-log |6+------------+71 row in set (0.00 sec)89mysql&gt; show variables where variable_name in (10 -&gt; 'innodb_buffer_pool_size',11 -&gt; 'innodb_log_buffer_size',12 -&gt; 'innodb_additional_mem_pool_size',13 -&gt; 'key_buffer_size',14 -&gt; 'query_cache_size'15 -&gt; );16+-------------------------+-----------+17| Variable_name | Value |18+-------------------------+-----------+19| innodb_buffer_pool_size | 134217728 |20| innodb_log_buffer_size | 16777216 |21| key_buffer_size | 8388608 |22| query_cache_size | 1048576 |23+-------------------------+-----------+244 rows in set (0.00 sec) innodb_buffer_pool_size：buffer pool的大小，默认值128MB，建议为总内存的80%(InnoDB还要为buffer pool预留一些空间供control structures使用，因此实际大小为设定值的110%左右) innodb_log_buffer_size：log buffer的大小，默认值8MB或16MB key_buffer_size：MyISAM表的索引缓冲区(key cache)大小，默认值8MB 1，key cache用于缓存MyISAM表的索引块，而MyISAM表的数据块是直接存放于操作系统文件缓存中的 2，如果大量使用MyISAM引擎的表，可将此值增大至总内存的25%，但不建议太大 3，调大此参数可以增加MyISAM表BULK INSERT的效率 4，通过观察状态变量Key_read_requests, Key_reads, Key_write_requests和Key_writes来了解key_buffer_size的设置是否合理，其中Key_reads/Key_read_requests的值应当小于0.1，Key_writes/Key_write_requests的值应当在1左右 5，key cache的碎片率计算公式如下，Key_blocks_unused是未使用的块数，key_cache_block_size是每个块的大小。下面公式值越大，说明key cache利用率越高，碎片率越小：1 - ((Key_blocks_unused * key_cache_block_size) / key_buffer_size) innodb_additional_mem_pool_size：存放数据字典和其它内部结构的内存大小，默认值8MB，它与innodb_use_sys_malloc参数有关联(两个参数在MySQL 5.7.4中被移除) 该参数被移除的原因：早期操作系统的内存分配器性能和可伸缩性较差，并且当时没有适合多核心CPU的内存分配器。所以InnoDB实现了一套自己的内存分配系统，做为内存系统的参数之一，引入了innodb_additional_mem_pool_size。随着多核心CPU的广泛应用和操作系统的成熟，操作系统能够提供性能更高、可伸缩性更好的内存分配器，包括Hoard、libumem、mtmalloc、ptmalloc、tbbmalloc和TCMalloc等。InnoDB实现的内存分配器相比操作系统的内存分配器并没有明显优势，所以在MySQL 5.7.4及之后的版本中，移除了innodb_additional_mem_pool_size 和 innodb_use_sys_malloc两个参数，统一使用操作系统的内存分配器 query_cache_size：查询缓存的大小，默认值1MB(MySQL 8.0.3中被移除) 该参数被移除的原因：整个查询缓存功能被移除 线程私有内存1mysql&gt; select version();2+------------+3| version() |4+------------+5| 5.7.25-log |6+------------+71 row in set (0.00 sec)89mysql&gt; show variables where variable_name in (10 -&gt; 'read_buffer_size',11 -&gt; 'read_rnd_buffer_size',12 -&gt; 'sort_buffer_size',13 -&gt; 'join_buffer_size',14 -&gt; 'binlog_cache_size',15 -&gt; 'binlog_stmt_cache_size',16 -&gt; 'bulk_insert_buffer_size',17 -&gt; 'thread_stack',18 -&gt; 'net_buffer_length',19 -&gt; 'myisam_sort_buffer_size',20 -&gt; 'preload_buffer_size'21 -&gt; );22+-------------------------+----------+23| Variable_name | Value |24+-------------------------+----------+25| binlog_cache_size | 32768 |26| binlog_stmt_cache_size | 32768 |27| bulk_insert_buffer_size | 8388608 |28| join_buffer_size | 262144 |29| myisam_sort_buffer_size | 8388608 |30| net_buffer_length | 16384 |31| preload_buffer_size | 32768 |32| read_buffer_size | 131072 |33| read_rnd_buffer_size | 262144 |34| sort_buffer_size | 262144 |35| thread_stack | 262144 |36+-------------------------+----------+3711 rows in set (0.00 sec)3839mysql&gt; show variables where variable_name in (40 -&gt; 'max_heap_table_size',41 -&gt; 'tmp_table_size'42 -&gt; );43+---------------------+----------+44| Variable_name | Value |45+---------------------+----------+46| max_heap_table_size | 16777216 |47| tmp_table_size | 16777216 |48+---------------------+----------+492 rows in set (0.00 sec) read_buffer_size：默认128KB，必须是4KB的倍数，具有如下功能： 1，对MyISAM引擎的表进行顺序读(sequential scan)的缓存区大小 2，MEMORY引擎表的MEMORY BLOCK SIZE大小 3，各种引擎的表在执行ORDER BY排序操作时，用于缓存索引数据的临时文件的大小 4，各种引擎的分区表在执行BULK INSERT时所使用的缓存区大小 5，用于缓存各种引擎的表的子查询结果集的缓存区大小 read_rnd_buffer_size：默认256KB，具有如下功能： 1，MRR所使用的排序buffer大小 2，对MyISAM引擎的表进行随机读的缓冲区大小。例如按照某字段的ORDER BY顺序对MyISAM表进行rowid排序时(参与排序的所有字段(包括select与order by字段)长度超过max_length_for_sort_data)，会先在Sort Buffer中按照需求进行排序，然后将rowid放入read_rnd_buffer_size管理的缓冲区中按照rowid再排序，最后再用有序的rowid回表，从而将随机读转化为顺序读(类似于MRR) sort_buffer_size：SQL语句用来进行内存排序操作(order by,group by)的buffer大小，默认256KB，过小会导致磁盘排序。如果增大了max_sort_length参数值(限定字段的前N个字节参与排序,尤其是针对BLOB和TEXT类型)，则sort_buffer_size值也应当增大 binlog_cache_size：存放每个线程自己transaction的binlog的缓存大小，默认32KB，如果有大事务可以调大 binlog_stmt_cache_size：存放每个线程自己的transaction中非事务语句的binlog event的缓存大小，默认32KB join_buffer_size：join buffer的大小，在BNL和BKA中，用于缓存驱动表的数据，默认256KB bulk_insert_buffer_size：用于提高MyISAM表的bulk insert操作(INSERT…SELECT，INSERT VALUES(),…,()，LOAD DATA)效率的cache tree大小，默认8MB tmp_table_size：内存临时表的大小上限(其实是由MIN(max_heap_table_size,tmp_table_size)决定的)，默认为16MB，超过会转变为磁盘临时表 max_heap_table_size：内存表的大小上限，默认16MB preload_buffer_size：预加载索引时分配的缓冲区大小，默认32KB myisam_sort_buffer_size：MyISAM表执行REPAIR TABLE和CREATE/ALTER INDEX时所使用的排序操作的buffer大小，默认8MB thread_stack：每个连接线程被创建时，MySQL给它分配的内存堆栈大小，默认256KB net_buffer_length：connection buffer和result buffer的初始大小，默认16KB，这两个缓冲区最大能够增长至max_allowed_packet参数指定的大小(4MB)，SQL执行完后收缩至net_buffer_length参数指定的大小 根据上面的描述，可以使用如下公式大致评估mysql进程可能使用的最大内存量(通常达不到这个值，因为极少可能出现大量线程同时使用内存临时表和bulk insert buffer等) 1## MOS文档(ID 1483601.1)中给出了如下公式：23Global Usage &#x3D; key_buffer_size + query_cache_size + 1.1 * innodb_buffer_pool_size + innodb_additional_mem_pool_size + innodb_log_buffer_size45Per Thread &#x3D; thread_stack + 2 * net_buffer_length67Note: the per query contribution is more or less based on an average query8Per Query &#x3D; &quot;buffer for reading rows&quot; + &quot;sorting&quot; + &quot;full joins&quot; + &quot;binlog cache&quot; + &quot;index preload&quot; + &quot;internal tmp tables&quot;9 &#x3D; max(read_buffer_size, read_rnd_buffer_size)10 + max(sort_buffer_size&#x2F;2, &quot;avg queries with scan&quot; * &quot;avg scans with merge&quot; * sort_buffer_size)11 + &quot;avg full joins&quot; * join_buffer_size12 + &quot;avg binlog cache use&quot; * binlog_cache_size13 + preload_buffer_size14 + &quot;avg tmp tables&quot; * min(tmp_table_size, max_heap_table_size)1516Total &#x3D; &quot;global&quot; + max_used_connections * (&quot;thread&quot; + &quot;query&quot;) MySQL与Hugepagehugepage介绍 大页内存的原理涉及到操作系统的虚拟地址到物理地址的转换过程。操作系统为了能同时运行多个进程，会为每个进程提供一个虚拟进程空间。为了保证进程能在内存中找到虚拟页对应的实际物理块，需要为每个进程维护一个映像表，即页表。页表记录了每一个虚拟页在内存中对应的物理块号。在配置好了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号 由于页表是存放在内存中的，这使CPU在每存取一个数据时，都要两次访问内存。第一次时访问内存中的页表，从中找到指定页的物理块号，再将块号与页内偏移拼接，以形成物理地址。第二次访问内存时，才是从第一次所得地址中获得所需数据。因此，采用这种方式将使计算机的处理速度降低近1/2 为了提高地址变换速度，可在地址变换机构中，增设一个具有并行查找能力的特殊高速缓存，即快表(TLB)，用以存放当前访问的那些页表项。由于成本的关系，快表不可能做得很大，通常只存放16~512个页表项 现代的计算机系统，都支持非常大的虚拟地址空间(2^32~2^64)。在这样的环境下，页表就变得非常庞大。例如，假设页大小为4K，对占用40G内存的程序来说，页表大小为10M，而且还要求空间是连续的。为了解决空间连续问题，可以引入二级或者三级页表。但是这更加影响性能，因为如果快表缺失，访问页表的次数由两次变为三次或者四次。由于程序可以访问的内存空间很大，如果程序的访存局部性不好，则会导致快表一直缺失，从而严重影响性能。此外，由于页表项有10M之多，而快表只能缓存几百页，即使程序的访存性能很好，在大内存的情况下，快表缺失的概率也很大。但是假设我们将页大小变为1G，40G内存的页表项也只有40，快表完全不会缺失！即使缺失，由于表项很少，可以采用一级页表，缺失只会导致两次访存。这就是大页内存可以优化程序性能的根本原因：提高快表(TLB)的命中率，减少内存访问次数 huge page优势 提高快表(TLB)的命中率，减少内存访问次数 hugepage是共享内存，它会被一直pin在内存中，避免被交换 为MySQL开启hugepage(Linux)InnoDB支持hugepage，可用于buffer pool和additional memory pool。测试环境的MySQL 5.7.25版本中已经没有innodb_additional_mem_pool_size参数，因此这里仅考虑buffer pool 1mysql&gt; select version();2+------------+3| version() |4+------------+5| 5.7.25-log |6+------------+71 row in set (0.01 sec)89mysql&gt; show variables where variable_name in (10 -&gt; 'innodb_buffer_pool_size',11 -&gt; 'innodb_additional_mem_pool_size');12+-------------------------+-----------+13| Variable_name | Value |14+-------------------------+-----------+15| innodb_buffer_pool_size | 536870912 |512MB16+-------------------------+-----------+171 row in set (0.00 sec)1819mysql&gt; show global variables like 'large_page%';20+-----------------+-------+21| Variable_name | Value |22+-----------------+-------+23| large_page_size | 0 |24| large_pages | OFF |25+-----------------+-------+262 rows in set (0.01 sec) 为了开启大页，首先建议关闭透明大页；如果如下两条命令的输出都是never，说明已经关闭transparent hugepage 1[root@rhel6 ~]# cat /sys/kernel/mm/transparent_hugepage/defrag2always madvise [never]3[root@rhel6 ~]# cat /sys/kernel/mm/transparent_hugepage/enabled4always madvise [never] 如果上述命令输出不是never，则在/etc/rc.local中追加如下内容(如果是Linux 7.x，则为/etc/rc.d/rc.local)，重启后再使用上述命令检查 1if test -f /sys/kernel/mm/transparent_hugepage/enabled; then2echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled3fi4if test -f /sys/kernel/mm/transparent_hugepage/defrag; then5echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag6fi 在/etc/security/limits.conf定义mysql用户的memlock为unlimited 1mysql soft memlock unlimited2mysql hard memlock unlimited 查看mysql用户的属组信息 1[root@rhel6 ~]# id mysql2uid=496(mysql) gid=504(mysql) groups=504(mysql) 编辑/etc/sysctl.conf，添加如下内容 1vm.hugetlb_shm_group=504 # mysql用户的gid2vm.nr_hugepages=512 # 512*2MB=1GB vm.nr_hugepages定义了hugepage的数量，它应当满足如下公式：nr_hugepages * Hugepagesize &gt; innodb_buffer_pool_size + innodb_additional_mem_pool_size 正确设置kernel.shmmax和kernel.shmall，编辑/etc/sysctl.conf，添加如下内容 1kernel.shmmax=1073741824‬ # 1GB2kernel.shmall=2097152 # 2097152*4096=8GB kernel.shmmax：单个共享内存段的最大值(字节)，应当大于要分给mysql使用的hugepage大小kernel.shmall：共享内存总页数，建议为物理内存大小的90%除以PAGE_SIZE(分页大小：getconf PAGE_SIZE)，应当大于：要分给mysql使用的hugepage大小/PAGE_SIZE 使上述配置生效，并检查大页是否按照预期配置开启。下面的输出表示OS支持并且已经开启大页功能，页面大小为2MB，共512个页，一共1GB大页内存。如果(AnonHugePages不为0，说明没关透明大页) 1[root@rhel6 ~]# sysctl -p2...3[root@rhel6 ~]# cat /proc/meminfo | grep -i huge4AnonHugePages: 0 kB5HugePages_Total: 5126HugePages_Free: 5127HugePages_Rsvd: 08HugePages_Surp: 09Hugepagesize: 2048 kB 在my.cnf中增加如下配置，并重启mysqld(这里innodb_buffer_pool_size设定的是512MB) 1large_pages&#x3D;ON 查看大页的使用情况 1##大页已使用512-498=14个，操作系统承诺会分配的大页还有254个，因此预计最大会分配14+254个页，大小为268*2MB=536MB大页内存2[root@rhel6 ~]# cat /proc/meminfo | grep -i huge3AnonHugePages: 0 kB4HugePages_Total: 512 ## 总的大页数量5HugePages_Free: 498 ## 未分配的大页数量6HugePages_Rsvd: 254 ## OS承诺会分配，但暂时还没分配的大页数量7HugePages_Surp: 08Hugepagesize: 2048 kB910------------------------------------------------------------------------11##top输出12Mem: 1907580k total, 1706188k used, 201392k free, 8724k buffers13Swap: 4095992k total, 27532k used, 4068460k free, 265224k cached1415 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1666287 mysql 20 0 1628m 184m 11m S 0.0 9.9 0:08.51 mysqld 1718mysql&gt; show global variables like 'large_page%';19+-----------------+---------+20| Variable_name | Value |21+-----------------+---------+22| large_page_size | 2097152 |2MB，等于Hugepagesize23| large_pages | ON |24+-----------------+---------+252 rows in set (0.00 sec) 执行一个大的SQL查询后，再次查看mysqld内存占用和大页使用情况 1##大页已使用512-445=67个，操作系统承诺会分配的大页还有201个，因此预计最大会分配67+201个页，大小为268*2MB=536MB大页内存2[root@rhel6 ~]# cat /proc/meminfo | grep -i huge3AnonHugePages: 0 kB4HugePages_Total: 5125HugePages_Free: 4456HugePages_Rsvd: 2017HugePages_Surp: 08Hugepagesize: 2048 kB910------------------------------------------------------------------------11##top输出12Mem: 1907580k total, 1755440k used, 152140k free, 192k buffers13Swap: 4095992k total, 42760k used, 4053232k free, 18308k cached1415 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1667078 mysql 20 0 1692m 184m 1664 S 0.3 9.9 0:08.69 mysqld Troubleshooting测试innodb_buffer_pool_size大于hugepage的情况： 1##保持innodb_buffer_pool_size=512M不变，修改/etc/sysctl.cnf中的vm.nr_hugepages=128，使大页总大小为256MB，小于了buffer pool大小2[root@rhel6 ~]# service mysqld stop3Shutting down MySQL.... [ OK ]4[root@rhel6 ~]# sysctl -p5...6[root@rhel6 ~]# cat /proc/meminfo | grep -i huge7AnonHugePages: 0 kB8HugePages_Total: 1289HugePages_Free: 12810HugePages_Rsvd: 011HugePages_Surp: 012Hugepagesize: 2048 kB1314##启动mysqld时，虽然可以成功启动，但是error.log中出现报错信息152019-12-11T09:56:30.182908Z 0 [Note] InnoDB: Initializing buffer pool, total size = 512M, instances = 1, chunk size = 128M162019-12-11T09:56:30.193825Z 0 [Warning] InnoDB: Failed to allocate 138412032 bytes. errno 12172019-12-11T09:56:30.193969Z 0 [Warning] InnoDB: Using conventional memory pool182019-12-11T09:56:30.201059Z 0 [Warning] InnoDB: Failed to allocate 138412032 bytes. errno 12192019-12-11T09:56:30.201139Z 0 [Warning] InnoDB: Using conventional memory pool202019-12-11T09:56:30.207174Z 0 [Warning] InnoDB: Failed to allocate 138412032 bytes. errno 12212019-12-11T09:56:30.207282Z 0 [Warning] InnoDB: Using conventional memory pool222019-12-11T09:56:30.218470Z 0 [Note] InnoDB: Completed initialization of buffer pool2324[root@rhel6 ~]# cat /proc/meminfo | grep -i huge25AnonHugePages: 0 kB26HugePages_Total: 12827HugePages_Free: 11928HugePages_Rsvd: 6129HugePages_Surp: 030Hugepagesize: 2048 kB3132##执行大查询后，大页有被使用的情况，说明即使大页比buffer pool小，也可以使用大页33[root@rhel6 ~]# cat /proc/meminfo | grep -i huge34AnonHugePages: 0 kB35HugePages_Total: 12836HugePages_Free: 6737HugePages_Rsvd: 938HugePages_Surp: 039Hugepagesize: 2048 kB referencehttps://dev.mysql.com/doc/refman/5.7/en/optimizing-memory.html How to estimate how much memory MySQL uses (文档 ID 1359675.1) Why is MySQL Using Less Memory Than Configured? (文档 ID 1483601.1)","categories":[{"name":"MySQL原理","slug":"MySQL原理","permalink":"https://ddhe9527.github.io/categories/MySQL%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://ddhe9527.github.io/tags/MySQL/"},{"name":"内存","slug":"内存","permalink":"https://ddhe9527.github.io/tags/%E5%86%85%E5%AD%98/"}]}]}